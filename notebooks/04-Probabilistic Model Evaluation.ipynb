{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probabilistic Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using deep learning models in production,\n",
    "we do not have the luxury of having access to ground-truth.\n",
    "However, it may be feasable to integrate a human domain expert\n",
    "into production workflows.\n",
    "\n",
    "In order to maximize throughput,\n",
    "we must be selective about when we alert our human expert.\n",
    "If we can understand the reliability of our model predictions\n",
    "as a function of its self-reported confidence,\n",
    "we can use this to guide business logic in our application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilistic Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chance of our model making a valid prediction\n",
    "can be thought of as a\n",
    "[Bernoulli](https://en.wikipedia.org/wiki/Bernoulli_distribution)\n",
    "random variable:\n",
    "\n",
    "$$\\text{Valid Prediction}, V_i \\sim \\text{Ber}( p(c_i) ), i=1..N$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $p(c_i)$ is a\n",
    "[logistic function](https://en.wikipedia.org/wiki/Logistic_function)\n",
    "of the prediction confidence:\n",
    "\n",
    "$$p(c) = \\frac{1}{1+e^{\\beta c + \\alpha}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use our ground-truth validations to evaluate\n",
    "the likelihood that a given *logistic function*\n",
    "with parameters $\\alpha$ and $\\beta$\n",
    "\"explains\" the data.\n",
    "\n",
    "This likelihood defines the following\n",
    "joint log probability optimization function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_joint_log_prob(validation, confidence, alpha, beta):\n",
    "    prior_alpha = tfp.distributions.Normal(loc=0., scale=10)\n",
    "    prior_beta = tfp.distributions.Normal(loc=0, scale=100)\n",
    "    \n",
    "    logistic_p = 1./(1. + tf.exp(beta * confidence + alpha))\n",
    "    expected = tfp.distributions.Bernoulli(probs=logistic_p)\n",
    "    \n",
    "    return (\n",
    "        prior_alpha.log_prob(alpha)\n",
    "        + prior_beta.log_prob(beta)\n",
    "        + tf.reduce_sum(expected.log_prob(validation))\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hamiltonian Monte Carlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hamiltonian_monte_carlo(\n",
    "    validation,\n",
    "    confidence,\n",
    "    num_steps=10000,\n",
    "    num_leapfrog_steps=4,\n",
    "    burnin=2000,\n",
    "):\n",
    "    # Initialize the HMC\n",
    "    initial_chain_state = [\n",
    "        0. * tf.ones([], name=\"init_alpha\"),\n",
    "        0. * tf.ones([], name=\"init_beta\"),\n",
    "    ]\n",
    "    \n",
    "    # Rescale \"beta\" to be 10x magnitude of \"alpha\"\n",
    "    unconstraining_bijectors = [\n",
    "        tfp.bijectors.Identity(),\n",
    "        tfp.bijectors.AffineScalar(scale=10),\n",
    "    ]\n",
    "    \n",
    "    # Create a closure with our input data\n",
    "    unnormalized_posterior_log_prob = (\n",
    "        lambda *args: validation_joint_log_prob(\n",
    "            validation,\n",
    "            confidence,\n",
    "            *args,\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Define the HMC\n",
    "    hmc = tfp.mcmc.TransformedTransitionKernel(\n",
    "        inner_kernel=tfp.mcmc.SimpleStepSizeAdaptation(\n",
    "            tfp.mcmc.HamiltonianMonteCarlo(\n",
    "                target_log_prob_fn=unnormalized_posterior_log_prob,\n",
    "                num_leapfrog_steps=num_leapfrog_steps,\n",
    "                step_size=1,\n",
    "            ),\n",
    "            num_adaptation_steps=int(burnin * 0.8),\n",
    "        ),\n",
    "        bijector=unconstraining_bijectors,\n",
    "    )\n",
    "    \n",
    "    # Sample from the chain\n",
    "    [\n",
    "        posterior_alpha,\n",
    "        posterior_beta,\n",
    "    ], kernel_results = tfp.mcmc.sample_chain(\n",
    "        num_results=num_steps,\n",
    "        num_burnin_steps=burnin,\n",
    "        current_state=initial_chain_state,\n",
    "        kernel=hmc,\n",
    "    )\n",
    "    \n",
    "    return posterior_alpha, posterior_beta, kernel_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Reasonable Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>confidence</th>\n",
       "      <th>validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.039997</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.603689</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.868116</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.133295</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.364439</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.767571</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.313861</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.196307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.718977</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.679592</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     confidence  validation\n",
       "0      0.039997           0\n",
       "1      0.603689           1\n",
       "2      0.868116           1\n",
       "3      0.133295           1\n",
       "4      0.364439           1\n",
       "..          ...         ...\n",
       "995    0.767571           1\n",
       "996    0.313861           1\n",
       "997    0.196307           0\n",
       "998    0.718977           1\n",
       "999    0.679592           0\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reasonable_data = pd.read_csv(\"validations/reasonable.csv\")\n",
    "reasonable_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mara/.local/share/virtualenvs/probabilistic-model-evaluation--jq05Z78/lib/python3.6/site-packages/tensorflow_probability/python/mcmc/sample.py:338: UserWarning: Tracing all kernel results by default is deprecated. Set the `trace_fn` argument to None (the future default value) or an explicit callback that traces the values you are interested in.\n",
      "  warnings.warn('Tracing all kernel results by default is deprecated. Set '\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "reasonable_alpha, reasonable_beta, kernel_results = (\n",
    "    hamiltonian_monte_carlo(\n",
    "        reasonable_data[\"validation\"],\n",
    "        reasonable_data[\"confidence\"],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "* https://colab.research.google.com/github/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/blob/master/Chapter2_MorePyMC/Ch2_MorePyMC_TFP.ipynb\n",
    "* https://www.tensorflow.org/probability/api_docs/python/tfp/mcmc/HamiltonianMonteCarlo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
